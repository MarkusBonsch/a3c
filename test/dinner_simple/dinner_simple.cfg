
## training setup
nWorkers: 4 ## number of workers that play games
nGames: 3000 ## number of games that each worker will play.

## hyperparameters
updateFrequency: 50 ## parameters are updated every 'updateFrequency' steps
rewardDiscount: 0.99 ## discount factor for future rewards
normRange: 20 # how many episodes are used to normalize the reward and advantage

## optimizer setup
optimizer: 'rmsprop'
optimizerArgs:
  learning_rate: 0.001
  gamma1: 0.9
  gamma2: 0
  centered: True
  clip_gradient : 

## organisation
outputDir: 'C:/users/markus_2/Documents/Nerding/python/a3c/test/dinner_simple/test_fullState_valid_meetScore_9Teams_9pad_normRange20_conv16_fc64_continued'       ## if None, no output is saved. Otherwise, the model and log are saved every saveInterval games.
saveInterval: 50                      ## model will be saved after saveInterval episodes.
verbose: False                         ## whether to store extended log with gradient and parameter info
trainerFile: 'C:/users/markus_2/Documents/Nerding/python/a3c/test/dinner_simple/test_fullState_valid_meetScore_9Teams_9pad_normRange20_conv16_fc64/35000/trainer.states' ## file with initial states for the trainer 